---
title: 基于文件系统的 Agent 上下文工程实践
description: 深度探讨为什么文件系统是构建可靠 AI Agent 的关键，以及如何通过文件系统解决上下文管理的核心挑战
date: 2025-11-21
author:
  name: Nick Huang
  url: https://blog.langchain.com
originalUrl: https://blog.langchain.com/how-agents-can-use-filesystems-for-context-engineering/
image: https://blog.langchain.com/content/images/size/w1200/2025/11/How-agents-can-use-a-filesystem.png
---

深度 Agent（Deep Agents）的一个核心特性是能够访问一系列文件系统工具。这些 Agent 可以利用这些工具在文件系统中读取、写入、编辑、列出和搜索文件。

在这篇文章中，我们将深入探讨为什么文件系统对 Agent 至关重要。为了理解文件系统的作用，我们需要先剖析当前 Agent 存在的短板。Agent 任务失败通常归结为两个原因：（a）模型本身不够强大，或（b）缺乏正确的上下文。**“上下文工程是一门精妙的艺术与科学，旨在为 Agent 的下一步操作，在上下文窗口中填充恰到好处的信息。”** 理解上下文工程及其潜在的失效模式，对于构建可靠的 Agent 至关重要。

### 上下文工程视角下的 Agent

理解现代 Agent 工程师职责的一个独特视角，就是[上下文工程](https://blog.langchain.com/the-rise-of-context-engineering/)。通常，Agent **有权访问**海量的上下文（如所有支持文档、所有代码文件等）。为了回答一个传入的问题，Agent **需要**其中一部分关键上下文（即包含回答问题所需信息的上下文）。在尝试回答该问题的过程中，Agent 会**检索**一部分上下文（将其加载到上下文窗口中）。

![Context Engineering Diagram](/reading/2025/11/Screenshot-2025-11-12-at-6.24.44---PM-1.png)

从这个视角来看，上下文工程可能在多个环节“失效”：

- **如果 Agent 需要的上下文不在其可访问的总上下文中**，Agent 注定无法成功。例如：客服 Agent 需要查阅某个特定文档页面来回答问题，但该页面尚未被索引。
- **如果 Agent 检索到的上下文未能包含其所需的关键信息**，Agent 将无法给出正确回答。例如：客服 Agent 需要的文档页面存在且已索引，但 Agent 未能成功检索到它。
- **如果 Agent 检索到的上下文远大于其实际所需的**，则造成了资源浪费（时间、Token，或两者兼有）。例如：客服 Agent 只需要一个特定页面，却检索了 100 个页面。

作为 Agent 工程师，我们的工作就是**让“红色区域”尽可能贴合“绿色区域”（确保 Agent 检索到的上下文是所需信息的最小超集）。**

在寻求分离合适上下文的过程中，我们会遇到几个具体挑战：

1. **Token 过量（检索上下文 >> 必要上下文）**

   有些工具（比如网页搜索）会返回大量 Token。几次网页搜索就能迅速在对话历史中积累数万个 Token。虽然你最终可能会遇到讨厌的 400 Bad Request 错误，但在此之前，你的 LLM 账单就已经飙升，性能也开始下降。

2. **需要海量上下文（必要上下文 > 支持的上下文窗口）**

   有时 Agent 确实需要大量信息才能回答问题。这些信息通常无法通过单次搜索查询返回，这就是为什么许多人转向“智能体搜索（Agentic Search）”的理念——让 Agent 重复调用搜索工具。问题在于，上下文量会迅速增长到无法全部塞入上下文窗口的程度。

3. **查找冷门/细分信息（检索上下文 ≠ 必要上下文）**

   Agent 可能需要引用埋藏在成百上千个文件中的冷门（Niche）信息来处理输入。Agent 如何可靠地定位这些信息？如果做不到，检索到的上下文就不是回答问题所需的。除了语义搜索，还有其他替代（或补充）方案吗？

4. **持续学习（总上下文 ≠ 必要上下文）**

   有时 Agent 可能就是没有回答问题所需的上下文（无论是在工具中还是指令中）。最终用户往往会在与 Agent 的交互中提供线索（隐式或显式），暗示可能需要什么样的上下文。有没有办法让 Agent 将这些信息添加到上下文中，供未来迭代使用？

这些都是常见的障碍，我们大多数人之前都遇到过这些问题的不同变种！

### 文件系统如何让 Agent 变得更强？

简而言之：**文件系统提供了一个统一的接口，Agent 可以通过它灵活地存储、检索和更新无限量的上下文。**

让我们看看它如何帮助解决上述每个场景。

**Token 过量（检索上下文 >> 必要上下文）**

Agent 可以将工具调用结果和笔记写入文件系统，而不是使用对话历史记录保存所有内容，然后在需要时选择性地查找**相关信息**。[Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus?ref=blog.langchain.com) 是首批公开讨论这种方法的人之一——下图来自他们的博客文章。

![Manus Context Engineering](/reading/2025/11/Manus-Context-Engineering.004-1.png)

回到网页搜索的例子。我运行一次网页搜索，从工具中得到 1 万个 Token 的原始内容。这些内容大部分可能并不是时刻都需要的。如果我把它放在消息历史中，这 1 万个 Token 会在整个对话中一直存在，推高我的 Anthropic 账单。但如果我把大型工具结果卸载（offload）到文件系统，Agent 就可以智能地 grep 搜索特定关键词，然后只将必要的上下文读入对话。

在这个例子中，Agent 实际上是将文件系统用作**大型上下文的草稿本。**

**需要海量上下文（必要上下文 < 支持的上下文窗口）**

有时 Agent 需要大量上下文才能回答问题。文件系统提供了一个很好的抽象，让 LLM 可以根据需要动态存储和提取更多信息。例如：

- 对于长时程任务，Agent 需要制定计划并遵循它。通过将计划写入文件系统，Agent 可以稍后将这些信息拉回上下文窗口，提醒自己应该做什么（例如[“通过复述来操纵注意力”](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus?ref=blog.langchain.com)）。
- 为了梳理所有这些上下文，Agent 可能会启动子 Agent。当这些子 Agent 工作并习得新知时，它们可以将知识写入文件系统，而不仅仅是向主 Agent 回复学习成果（例如[最小化“传话游戏”中的信息损耗](https://www.anthropic.com/engineering/multi-agent-research-system?ref=blog.langchain.com)）。
- 有些 Agent 需要关于如何执行任务的大量指令。你可以将这些指令存储为文件，让 Agent 根据需要动态读取，而不是将所有指令塞进系统提示词（导致上下文膨胀）（例如 [Anthropic 技能](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills?ref=blog.langchain.com)）。

**查找冷门/细分信息（检索上下文 ≠ 必要上下文）**

语义搜索是 LLM 浪潮早期最流行的上下文检索方法之一。它在某些用例中可能有效，但根据文档类型（例如技术 API 参考、代码文件），由于文本中缺乏语义信息，语义搜索可能表现不佳。

文件系统提供了一种替代方案，允许 Agent 使用 `ls`、`glob` 和 `grep` 工具智能地搜索上下文。如果你最近使用过 Claude Code，你会知道它严重依赖 glob 和 grep 搜索来精准定位所需的上下文。这种技术成功的关键在于：

- 当今的模型经过[专门训练](https://platform.claude.com/docs/en/agents-and-tools/tool-use/bash-tool?ref=blog.langchain.com)，能够理解如何遍历文件系统。
- 信息通常已经按逻辑结构化（目录）。
- Glob 和 grep 允许 Agent 不仅隔离特定文件，还能隔离特定的行和字符。
- [`read_file`](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool?ref=blog.langchain.com) 工具允许 Agent 指定从文件中读取哪些行。

由于这些原因，在某些情况下，使用文件系统（以及通过使用文件系统获得的搜索能力）可以产生更好的结果。

注意，语义搜索仍然有用！并且可以与文件系统搜索结合使用。Cursor 最近[写了一篇博客](https://cursor.com/blog/semsearch?ref=blog.langchain.com)强调了同时使用两者的好处。

**持续学习（总上下文 ≠ 必要上下文）**

Agent 出错的一个主要原因是缺少相关上下文。改进 Agent 的一个好方法通常是确保它们能够访问正确的上下文。有时这可能意味着添加更多数据源或更新系统提示词。

更新系统提示词的常见做法是：

1. 发现 Agent 缺少适当指令的例子。
2. 从领域专家（SME）那里获取相关指令。
3. 用这些指令更新提示词。

很多时候，最终用户实际上是最好的领域专家。通过与 Agent 的对话，他们可能会提供重要线索（隐式或显式），暗示正确的相关指令是什么。所以考虑到这一点——有没有办法自动化上面的第三步（用这些指令更新提示词）？

我们认为，Agent 的指令（或技能）与它们可能想要处理的任何其他上下文没有区别。文件系统可以作为 Agent 存储和更新自己指令的地方！

在收到用户反馈后，Agent 可以立即写入自己的文件并记住一条重要信息。这对于快速的、一次性的事实特别有用，尤其是那些可能是用户自定义的内容，比如他们的姓名、电子邮件或其他偏好。

这还没有完全解决，仍然是一个新兴模式，但这是 LLM 随时间增长自己技能组合和指令的令人兴奋的新方式，确保在未来的迭代中它们能够访问必要的上下文。

### 看看深度 Agent 如何利用文件系统

我们有一个名为 Deep Agents 的开源仓库（[Python](https://github.com/langchain-ai/deepagents?ref=blog.langchain.com)、[TypeScript](https://github.com/langchain-ai/deepagentsjs?ref=blog.langchain.com)），可以让你快速构建一个能够访问文件系统的 Agent。许多使用文件系统的上下文工程技巧都已经内置其中！肯定还会涌现出更多模式——试试 Deep Agents，告诉我们你的想法！
