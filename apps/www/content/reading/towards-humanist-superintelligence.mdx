---
title: "迈向人文主义超级智能"
description: "Microsoft AI CEO Mustafa Suleyman 深度解析“人文主义超级智能”（HSI）：一种专注于解决具体问题、受控且始终服务于人类福祉的 AI 演进范式，拒绝盲目的 AGI 军备竞赛。"
date: 2025-11-07
author:
  name: "Mustafa Suleyman"
  url: "https://mustafa-suleyman.ai/"
originalUrl: "https://mustafa-suleyman.ai/a-humanist-future"
image: "https://mustafa-suleyman.ai/_next/image?url=%2Fimages%2Fposts%2Fimage-(16).jpg&w=3840&q=60"
category: humanity
---

### 人文主义的未来

有一个问题并未得到应有的关注，但这可能也是我们这个时代最重要的问题：<strong>世界究竟需要什么样的 AI？</strong>

过去几年，技术进步的步伐令人惊叹。我们正轻而易举地跨越一个个伟大的里程碑。作为 AI 领域 70 年来的灵感灯塔，图灵测试（Turing Test）实际上在毫无喧哗和认可中已被悄然通过。随着[推理模型](https://epoch.ai/gradient-updates/how-far-can-reasoning-models-scale)（reasoning models）的问世，我们在通往超级智能（Superintelligence）的旅程中跨越了一个关键的转折点。如果说 AGI（通用人工智能）通常被视为 AI 在所有任务上匹敌人类能力的时刻，那么超级智能则意味着它将远远超越这一表现。

与其无休止地争论能力边界或时间表，我们现在更应深思技术的宗旨：我们要从技术中获得什么？它的界限应在何处？我们如何确保这股惊人的技术力量始终造福人类？

在 Microsoft AI，我们正致力于构建<strong>人文主义超级智能（Humanist Superintelligence, HSI）</strong>：即那些拥有极其先进能力，但始终为人服务、为更广泛的人类福祉效力的 AI。我们将其构想为<strong>面向问题（problem-oriented）</strong>且倾向于<strong>特定领域（domain-specific）</strong>的系统。它不是一个拥有高度自主权、无边界、无限制的实体，而是一种经过精心校准、语境化且处于限定范围内的 AI。我们要探索并确立一种路径：既能让最先进的 AI 形式保持在人类的掌控之下，又能加速我们应对全球最紧迫挑战的进程。

为此，我们组建了由我领导的 Microsoft AI 超级智能团队（MAI Superintelligence Team）。我们的目标是将其打造为全球无可争议的最佳 AI 研究与构建基地。我将其定义为“人文主义超级智能”，是为了明确指出：这并非追求某种没有方向的技术目标，不是为了攀登高峰而攀登高峰的空洞挑战。我们这样做是为了解决现实具体的问题，并确保其方式是脚踏实地且可控的。我们构建的不是某种定义模糊、虚无缥缈的超级智能，而是一种明确设计为仅服务于人类的实用技术。

在此过程中，我们拒绝参与所谓的 AGI 军备竞赛叙事，而是将其视为改善生活和未来前景的更广泛、更深刻的人类事业的一部分。我们也拒绝“繁荣”与“毁灭”的二元对立；我们要在这个长期的过程中，为数十亿人带来切实、具体且安全的利益。我们要把这件事做对，这是我们深感肩负的责任。

人文主义的历史在于其持久的能力：以此对抗正统观念、极权主义倾向和悲观主义，帮助我们捍卫人类尊严，以及追求道德进步的理性自由。秉承这一精神，我们认为这种方法将帮助人类解锁 AI 几乎所有的益处，同时规避最极端的风险。

### 攀登指数级增长的陡坡

进步的速度令人瞠目。今年，仿佛 AI 领域的每个人都在谈论超级智能的曙光。这样的系统将拥有开放式的“学会学习”（learning to learn）能力——这是一种终极的元技能（meta skill）。因此，它可能会持续自我进化，在所有可想见的活动中远远超越人类水平。它将比我们所知的一切都更有价值。

但这一切是为了什么？

对于人类而言，奖赏是巨大的：一个生活水平和科学技术飞速进步的世界，一个新艺术形式、文化和增长迸发的时代。这是一个真正令人振奋的使命，也是几十年来一直激励我的动力。我们应该歌颂并加速技术发展，因为它是历史上推动人类进步的最伟大引擎。这也是为什么我们需要更多、更多的技术。

在过去的 250 年里，我们的智慧推动了最美妙的科学发现和创业应用进程，将人类预期寿命从 [30 岁提升至 75 岁](https://ourworldindata.org/life-expectancy)。正是我们的智慧和发明的技术，为从 [10 亿增长到 80 亿](https://ourworldindata.org/grapher/population)的人口提供了食物、光明、住所、医疗、娱乐和知识。

技术让我们能够飞越全球，用抗生素治疗感染，凝视外太空的最深处，甚至与数百万素未谋面的人分享一张猫咪表情包。走进任何现代超市、医院、学校或办公室，你所看到的都是人类智慧的奇迹。AI 是这一旅程的下一阶段。这正是 Satya 所说的将全球 GDP 增长率提升至 [10%](https://www.dwarkesh.com/p/satya-nadella) 的含义；这是一种变革性的助推。作为“平台之上的平台”，这是微软赋能他人在全球范围内创造和发明这一核心使命的关键。

因此，当你听到关于 AI 的讨论时，请记住这一点。这是为了让我们集体成为更好的自己。AI 是实现人人享有更好医疗的途径。AI 是我们社会实现升级、逃离日益严重的零和博弈世界的方式。它是我们发展经济以广泛增加财富，并提升全社会生活水平的手段。或者换句话说：如果把 AI 排除在外，未来几十年的收益将变得难以企及。它是人类创造力和发明长路上的下一步，将拓展我们可以制造、思考和行动的边界。它是我们发现新能源发电方式、新娱乐模式的途径。

AI——或者说 HSI——是我们重建世界的方式。

### 必要的管控

与此同时，我们必须扪心自问：我们要如何<strong>管控（contain，即保障安全和控制）</strong>，更不用说<strong>对齐（align，即让它充分“在乎”人类而不造成伤害）</strong>一个在设计上旨在不断变得比我们更聪明的系统？对于那些拥有自主性、不断进化并通晓我们科学与社会方方面面的系统，我们根本不知道会从中涌现出什么。

既然这种超级智能可以持续自我进化，我们就需要不仅仅一次，而是持续地、永久地对其进行管控和对齐。

事情变得更加复杂。这不仅仅是今天前沿 AI 研究实验室中的“我们”需要做的事。全人类都需要一起做，时刻做。每一家商业实验室、每一家初创公司、每一个政府，都需要对对齐和管控项目保持持续的警惕和参与，这甚至还没算上那些恶意行为者和疯狂的车库修补匠（garage tinkerers）。

我遇到的任何 AI 开发者、安全研究员、政策专家或个人，都没有对“我们如何保证它是安全的？”这个问题给出令人放心的答案。如果你觉得这过于戏剧化，我很乐意听听你的反驳。也许我遗漏了什么。

创造超级智能是一回事；但与其同步建立可证明、稳健的管控与对齐机制，是 21 世纪人类面临的紧迫挑战。在找到答案之前，我们需要了解摆在我们面前的所有路径——无论是通向超级智能的，远离它的，还是通向某种完全替代形式的路径。

### 技术的宗旨

技术的宗旨是推动人类文明的进步。它应该帮助每个人过上更幸福、更健康的生活。它应该帮助我们创造一个人类与环境真正繁荣共存的未来。

我想阿尔伯特·爱因斯坦（Albert Einstein）说得最好，他[曾言](https://www.goodreads.com/quotes/7390795-why-does-this-magnificent-applied-science-which-saves-work-and)：“对人的关心及其命运，必须始终成为一切技术努力的主要目标……以便我们心智的创造物成为人类的祝福，而非诅咒。”

任何无法实现这一点的技术都是失败的。我们应该拒绝它。

这仍然是即将到来的超级智能浪潮的试金石，也是我们必须反复追问的问题：我们如何确信，这项技术带来的益处将远大于害处？随着未来几年我们越来越接近超级智能，我们有多大把握不会失控？谁来做这个评估？最重要的是，在这些问题的不确定性中，我们应该构建什么样的超级智能，并设定什么样的限制和护栏？

这些问题是 MAI 超级智能团队一切工作的核心，并指导着我们日常的决策。人类的核心长远利益应明确优先于任何研发议程。

### 迈向人文主义超级智能

我认为，我们要更好地构想一个世界上大多数人真正向往的未来。

人文主义超级智能（HSI）提供了一种替代愿景，它锚定于不可妥协的“以人为本”和对加速技术创新的承诺……但顺序至关重要。<strong>顺序就是关键。</strong> 这意味着先主动避免伤害，然后再加速。

HSI 并非设计用来在所有任务上击败所有人类并主宰一切，而是始于解决特定的社会挑战，以提升人类福祉。我们[最近发表](https://arxiv.org/html/2506.22405v1)的关于专家级 AI 医疗诊断的论文，就是这一方向的绝佳例证（下文详述）。

这清晰地展示了通往医疗超级智能的进步迹象，当它投入生产时，将真正带来变革。然而，由于它被设想为一系列更专注的<strong>特定领域超级智能（domain specific superintelligences）</strong>，它带来的对齐或管控挑战就不那么严峻。

简而言之，HSI 旨在获取科学和发明的所有美好，同时剔除“不可控风险”的部分。我们希望，这是该领域的一种常识性路径。

必须要宣示这一点似乎有些荒谬，但 HSI 是一种确保人类始终处于食物链顶端的愿景。这是一种 AI 始终站在人类一边的愿景。它始终为我们所有人工作。它有助于支持和增加人类的角色，而不是像一些人日益担心的那样剥夺它们；它让我们变得更聪明，而不是相反。无论前沿安全和对齐研究的现状如何，它始终服务于我们的利益，让我们的星球更健康、更富裕，并保护我们脆弱的自然环境。

我们有责任为未来交付一个比我们继承时明显更好的世界。有时我们很容易忽视技术已经带来的惊人成就。当你因为办公室空调太冷而穿上外套，或者在假期机场值机排队时感到沮丧，又或者为智能电视上看什么而纠结时：这都是技术赋予我们的非凡特权。每一刻都会让我们的祖先感到困惑。我们的抱怨也是如此。如果我们做对了，类似的事情将再次成为可能。

### 人文主义超级智能将在何处发挥作用

以下是激励 Microsoft AI 的三个应用领域。当然，还有更多领域，我将在未来概述。

<strong>每人专属的 AI 伴侣（An AI companion for everyone）</strong> —— 每一个想要的人都将拥有一个完美且廉价的 AI 伴侣，帮助你学习、行动、提高生产力并获得支持。我们许多人感到被日常的精神负担压垮；不知所措、分心；被永无止境的信息鼓点和压力搅得心神不宁。如果我们做对了，AI 伴侣将帮助分担这些重负，完成任务，并成为一个个人的、富有创造力的参谋。AI 伴侣将是个性化的，适应我们的生活轮廓，但在为了你的最大利益时也不惧反驳；它的构建初衷是始终支持而非取代人际连接，其核心设计理念是信任与责任。

AI 伴侣还将对我们的学习方式产生深远影响。它们将配合每一位学生的优势和劣势，与教师并肩工作，确保学生发挥全部潜能并鼓励他们的求知欲。这意味着量身定制的学习方法、适应性课程和完全个性化的练习。“一刀切”的教育对下一代来说，将像死记硬背拉丁语对我们一样奇怪。

<strong>医疗超级智能（Medical Superintelligence）</strong> —— 我们将在未来几年看到医疗超级智能的到来。这是我们需要胜过一切的特定领域人文主义超级智能。我们将在全方位的诊断以及临床运营环境中的高能力规划和预测方面拥有专家级的表现。自从我从事 AI 工作以来，解决这一挑战一直是我的热情所在。这意味着世界级的临床知识和干预/治疗将无处不在。

正如我上面提到的，我们[最近的工作](https://microsoft.ai/new/the-path-to-medical-superintelligence/)展示了这种更窄形式的特定领域超级智能的价值。《新英格兰医学杂志》（The New England Journal of Medicine）每期都包含一个病例挑战（Case Challenge）——列出症状和患者供诊断。这极其困难，即使是领域专家，通过率也仅有个位数百分比，更不用说普通医生了。我们的编排器 <strong>MAI-DxO</strong> 在这些病例挑战中达到了 85% 的准确率。人类医生的上限约为 20%，并且需要开具更多昂贵的检查。在我们看来，临床医生和患者都会欢迎这种额外的支持。这项工作只是暗示了其彻底变革医疗保健的潜力。

<strong>充裕的清洁能源（Plentiful clean energy）</strong> —— 能源驱动着一切成本。我们需要更多、更便宜、更清洁的能源。据估计，到 2050 年电力消耗将增长 [34%](https://www.instituteforenergyresearch.org/international-issues/eia-expects-global-energy-consumption-to-increase-through-2050/)，这在很大程度上是由数据中心需求的[增长](https://www.iea.org/news/ai-is-set-to-drive-surging-electricity-demand-from-data-centres-while-offering-the-potential-to-transform-how-the-energy-sector-works)驱动的。我预测，我们在 2040 年之前将拥有廉价且充裕的可再生能源发电和存储，而 AI 将在实现这一目标中发挥重要作用。它将帮助创建和管理新的工作流，以设计和部署新的科学突破。这些进步将帮助[生产](https://institute.global/insights/climate-and-energy/greening-ai-a-policy-agenda-for-the-artificial-intelligence-and-energy-revolutions)从新型负碳材料到更便宜更轻便的[电池](https://azure.microsoft.com/en-us/blog/quantum/2024/01/09/unlocking-a-new-era-for-scientific-discovery-with-ai-how-microsofts-ai-screened-over-32-million-candidates-to-find-a-better-battery/)等一切事物，并极大地提高现有资源（如电网基础设施、水系统、制造流程和供应链）的利用效率。它将建议并帮助实施大规模可行的碳去除策略。AI 还将推动突破，最终攻克[核聚变](https://www.microsoft.com/en-us/research/blog/microsoft-fusion-summit-explores-how-ai-can-accelerate-fusion-research/)能源难题。

这些突破与 HSI 一起到来，将深刻改善我们的文明。它们将为数十亿人带来变革性的差异。这一个十年很可能是历史上生产力最高的十年。然而，风险的增长速度也前所未有。

### 更安全的超级智能

在精确阐明我们应该构建何种超级智能的同时，现在也到了考虑我们需要围绕这一过程建立什么样的社会边界、规范和法律的时候了。在 MAI，这是一个我们欢迎的讨论和一系列行动。

这样做需要在巨大的竞争压力和机遇环境中做出真正的权衡和艰难的决定。在实现愿景和规避弊端方面存在无数挑战和障碍，包括招聘、安全、思维模式、市场结构以及校准最佳研究路径（在利用优势和避免劣势之间掌舵）。目前存在一个集体行动问题，即更不安全的超级智能模型可能会发展得更快并更自由地运作。

与所有此类问题一样，克服这一挑战极其艰巨，需要跨公司、跨政府以及更广泛层面的有意义的协调。但我相信，这始于愿意公开愿景，愿意与领域内的其他人、监管机构和公众进行对话。这就是我发表这篇文章的原因——开启一个过程，并明确表示我们不是在不惜一切代价、毫无限制地构建超级智能。关于这一切还有很多要说的（当然还有要做的），在接下来的几个月和几年里，你可以期待我和 MAI 更坦诚地解释和探索我们在这一领域的工作。

### 人类重于 AI

归根结底，HSI 需要行业转变其方法。构建 AI 的人是在为 AI 优化，还是为人类优化？谁来评判？在 Microsoft AI，我们相信<strong>人类重于 AI（humans matter more than AI）</strong>。我们希望构建的 AI 能深刻反映我们赋能地球上每一个人的更广泛使命。

人文主义超级智能将我们人类置于图景的中心。它是站在人类团队一边的 AI，是一个从属的、可控的 AI，一个不会、也不能打开潘多拉魔盒的 AI。受控（Contained）、价值对齐（Value aligned）、安全（Safe）——这些是基础，但还不够。HSI 让人类始终掌握方向盘。通过针对特定领域进行优化，并对自主性实施真正的限制，我的希望是这可以避免一些风险，并为人类的繁荣留出宝贵的空间，让我们像往常一样不断改进、参与和尝试。

解锁最先进 AI 形式的真正益处，不是我们独自就能完成的。当赌注如此之高时，问责制和监督是受欢迎的。超级智能可能是史上最好的发明——但前提是它将人类的利益置于一切之上。前提是它服务于人类。

这就是我相信世界想要的超级智能——人文主义的、应用型的超级智能。这也是我想构建的超级智能。这就是我们要在 MAI 超级智能团队构建的超级智能。
