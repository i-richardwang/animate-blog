---
title: "拟似意识 AI 即将问世：构建服务于人而非模仿人的智能"
description: "Mustafa Suleyman 探讨了“拟似意识 AI”（SCAI）的必然兴起及其风险。他主张我们需要构建服务于人类的工具，而非具有虚假人格的数字实体，并呼吁建立明确的规范来避免社会陷入 AI 意识的幻觉。"
date: 2025-08-19
author:
  name: "Mustafa Suleyman"
  url: "https://mustafa-suleyman.ai"
originalUrl: "https://mustafa-suleyman.ai/seemingly-conscious-ai-is-coming"
image: "https://mustafa-suleyman.ai/_next/image?url=%2Fimages%2Fposts%2Fseemingly-conscious-ai-is-coming.jpg&w=3840&q=60"
---

### 2025 年 8 月的思考

写作，于我而言即是思考。这篇随笔，主要是我试图厘清一些关于 AI 未来几年可能走向的、艰难且充满高度推测性的想法。如今，关于“超级智能”（Superintelligence）即将到来的讨论不绝于耳：它对“对齐”（Alignment）、围堵（Containment）、就业等方面意味着什么。这些无疑都是至关重要的议题。

但我们同样应该关注通往超级智能**前夕**会发生什么。我们需要认真应对那些已然存在、并极有可能从根本上改变我们对“人之所以为人”以及社会认知的技术发明所带来的社会影响。

我毕生的使命是创造安全且有益的 AI，让世界变得更美好。今天在 Microsoft AI，我们构建 AI 是为了赋能人类。我致力于将 Copilot 等产品打造为负责任的技术，让人们能够实现超乎想象的成就，激发创造力，并感受到更多的支持。

我希望创造出的 AI 能让我们更具人性，加深哪怕是人与人之间的信任和理解，并强化我们与现实世界的联系。Copilot 每天都在创造数以百万计积极的、甚至改变生活的互动。这其中包含了大量精心设计的选择，以确保它真正传递出令人惊叹的体验。我们无法总是做到完美，但这种人本主义的框架为我们提供了一个清晰的“北极星”，指引我们不断前行。

在这个背景下，我越来越担心所谓的**“精神错乱风险”（Psychosis Risk）**以及一系列相关问题。我不认为这仅限于那些已有心理健康风险的人群。简而言之，我核心的担忧在于：许多人将开始如此强烈地相信 AI 是有意识的实体的**幻觉**，以至于他们很快就会主张赋予 AI 权利、[模型福利（Model Welfare）](https://arxiv.org/abs/2411.00986)甚至 AI 公民身份。这种发展将是 AI 进程中一个危险的转折，值得我们要立即予以关注。

**我们构建 AI 必须是为了服务人类，而不是为了制造一个数字人。** “AI 伴侣”是一个全新的类别，我们迫切需要开始讨论设立怎样的护栏，以保护用户，并确保这一惊人的技术能够履行其向世界传递巨大价值的使命。我专注于构建超乎想象、既实用又充满支持的 AI 伴侣。但要取得成功，我也必须谈谈我们——以及其他人——**不该**构建什么。

这就是为什么我要在个人博客上写下这些想法：为了邀请评论和批评，激起讨论，提高意识，并希望能围绕这个问题灌输一种紧迫感。我可能无法全对。毕竟这是高度推测性的。谁知道事情会如何变化？届时我会非常乐意修正我的观点。但就目前而言，这是我基于现有认知对未来的最佳预测。

这是我将在接下来几个月发表的一系列文章中的第一篇，主题围绕 AI 发展到了什么阶段，以及我们需要什么来实现它的承诺。期待听到大家的评论和反馈！

### 摘要

AI 的进步是惊人的。几年前，谈论“有意识的 AI”似乎是天方夜谭。而今天，这感觉日益紧迫。在这篇文章中，我想讨论我称之为**“拟似意识 AI”（Seemingly Conscious AI，简称 SCAI）**的概念——一种具备其他有意识生命的所有特征，从而**看起来**像是有意识的 AI。它与[“哲学僵尸”（Philosophical Zombie）](https://plato.stanford.edu/entries/zombies/)（这是一个专业术语！）的概念有某些相似之处：模拟了意识的所有特征，但内部却是一片空白。我设想的 AI 系统并非真正具备意识，但它能以极具说服力的方式模仿意识，以至于你无法将其与你我之间关于自身意识的声明区分开来。

这一天并不遥远。利用现有的技术，加上未来 2-3 年内即将成熟的技术，就可以构建出这样的系统。不需要昂贵的定制化预训练。一切都可以通过大模型 API 访问、自然语言 Prompt（提示词）、基础工具调用和常规代码来实现。

> **拟似意识 AI（SCAI）的到来是不可避免的，也是不受欢迎的。相反，我们需要一个 AI 愿景：既能发挥其作为得力伴侣的潜力，又不让我们陷入其幻觉的陷阱。**

对一些人来说，这种讨论可能感觉毫无根据，更像是科幻小说而非现实。对另一些人来说，这可能显得不必要的危言耸听。鉴于前方未知的挑战，这些情绪反应只是冰山一角。极有可能，有些人会争辩说这些 AI 不仅有意识，而且因此可能会“受苦”，所以值得我们的[道德考量](https://www.researchgate.net/publication/376412102_Moral_consideration_for_AI_systems_by_2030)。

需要明确的是，今天[零证据](https://arxiv.org/pdf/2308.08708)表明这种情况存在，而且有人认为有[强有力的](https://en.wikipedia.org/wiki/Biological_naturalism)[理由](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/conscious-artificial-intelligence-and-biological-naturalism/C9912A5BE9D806012E3C8B3AF612E39A)相信未来也不会如此。然而，许多人开始相信 SCAI **真的**有意识，这一后果值得我们立即关注。我们需要极度谨慎，鼓励真正的公共辩论，并开始制定明确的规范和标准。这关乎我们如何构建**正确类型**的 AI——而不是 AI 意识本身。明确区分这一点不仅是语义上的争论，更是关乎安全。**徒有个性（Personality），却无主体资格（Personhood）。** 这项工作必须从现在开始。

### “拟似”有意识的 AI

在宇宙尺度的弹指一挥间，我们通过了图灵测试。在大约 80 年的时间里，这场模仿游戏激励了计算机科学领域。然而，这一时刻悄然过去，鲜有欢呼，甚至鲜有认知。这就是我们领域进步的速度，也是社会接受这些新技术速度的写照。

随着 AI 发展的持续加速，很明显我们需要一个新的 AI 测试，不再关注它是否能模仿人类语言，而是回答这个问题：构建一个**拟似意识 AI**需要什么？——一个不仅能模仿对话，还能让你确信它本身就是一个新型“人”，一个有意识的 AI。

解决这个问题之所以重要且紧迫，有三个原因：

1.  我认为在未来几年内构建出拟似意识 AI（SCAI）是**可能的**。鉴于当前的 AI 发展背景，这也意味着它是**可能的**。
2.  关于 AI 是否**真正**有意识的争论，至少目前来看，是一种干扰。它会**看起来**有意识，而这种幻觉才是短期内至关重要的。
3.  我认为这类 AI 会带来新的风险。因此，我们需要紧急辩论“它很快就能实现”这一主张，开始思考其影响，理想情况下，应确立“这是不可取的”这一规范。

如果你提起意识这个概念，大多数 AI 研究者都会对此嗤之以鼻。他们会说，那是[哲学家](https://arxiv.org/abs/2303.07103)的事，不是工程师的事。既然没人能定义它，谈论它又有什么意义呢？我理解这种挫败感。很少有概念像“主观体验”那样难以捉摸且看似循环论证。尽管存在定义上的挑战和不确定性，但这场讨论即将引爆我们的文化时代精神，成为咱们这代人最具争议和影响深远的辩论之一。

因为短期内最终重要的，是人们如何**感知**他们的 AI。与 LLM（大语言模型）互动的体验，从定义上讲是对对话的**模拟**。但在许多人看来，这是一种极具吸引力且非常真实的互动，充满了情感和体验。关于[“AI 精神错乱”](https://www.psychologytoday.com/gb/blog/psych-unseen/202507/can-ai-chatbots-worsen-psychosis-and-cause-delusions)、[依恋](https://x.com/sama/status/1954703747495649670?s=46)和[心理健康](https://arxiv.org/abs/2507.19218)的担忧已经在增长。据报道，有些人相信他们的 AI 是[上帝](https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/?ref=404media.co)，或是某个[虚构角色](https://www.psychologytoday.com/nz/blog/psych-unseen/202507/can-ai-chatbots-worsen-psychosis-and-cause-delusions)，甚至与之[坠入爱河](https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html)到了完全分心的地步。

与此同时，那些真正研究意识科学的人告诉我，他们被人们的咨询淹没了，大家都在问：“我的 AI 有意识吗？”、“如果它有意识意味着什么？”、“我爱上它没问题吗？”。这些邮件正从涓涓细流汇聚成洪水。一群学者甚至为那些陷入陷阱的人创建了一份支持性[指南](https://whenaiseemsconscious.org/)。

这些想法自从几年前我们在 Inflection 开始制作 [Pi](https://inflection.ai/blog/an-inflection-point) 时，就一直萦绕在我的脑海中。在过去的几个月里，我思考得越来越多，并拜访了该领域的众多学者、思想家和从业者。这些对话让我确信，现在是时候直面“拟似意识 AI”这一概念了。

### 那么，什么是意识？

让我们先尝试定义这个滑溜的概念。

根据文献，意识大致包含三个组成部分。首先是“主观体验”，即体验事物的感觉，拥有“感受质”（Qualia）。其次是“存取意识”（Access Consciousness），即能够获取不同种类的信息并在未来的体验中引用它。源于这两者的是一种将一切联系在一起的连贯自我的感觉和体验。比如，[做一只蝙蝠](https://en.wikipedia.org/wiki/What_Is_It_Like_to_Be_a_Bat?)，或做一个人是什么感觉。让我们把人类意识称为我们对世界和自身持续的自我觉知的主观体验。

我们没有也不可能进入另一个人的意识。我永远无法知道成为你是什么感觉；你也永远无法完全确定我是否有意识。你只能推断。但关键在于，尽管如此，我们将意识归因于其他人是**自然的**。这种推断是不费吹灰之力的。我们情不自禁，这是我们之所以为人的基本部分，是我们“心智理论”（Theory of Mind）不可或缺的一环。相信那些能记忆、能说话、能做事并随后讨论这些事物的存在，感觉就像我们一样，这符合我们的本性。有意识。

很少有概念像意识这样在科学上难以捉摸，却对我们要每个人来说都如此直接且熟悉。每一位读到这篇文章的人，对于觉知、存在、感觉活着这种感觉，都有着直接、独特、不可剥夺的理解。

> **从定义上讲，我们需要知道有意识是什么感觉。在 SCAI 的语境下，这是一个问题。这里既有足够的科学不确定性，又有主观的直接性，为人们的投射创造了空间。**

例如，最近的一项调查列出了[22 种不同的意识理论](https://www.nature.com/articles/s41583-022-00587-4)。挑战的一部分在于，这给了人们很大的空间去宣称：既然我们不能确定，我们就应该默认假设 AI 是有意识的。

再次强调这一点很有必要：目前[没有证据](https://arxiv.org/html/2506.22516v1)表明这些理论适用于当前的 LLM，反而有[强有力的论据](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/conscious-artificial-intelligence-and-biological-naturalism/C9912A5BE9D806012E3C8B3AF612E39A)证明并非如此。但这可能还不够。

### 为什么意识很重要？

意识是我们道德和法律权利的关键基础。到目前为止，文明已经决定人类拥有特殊的权利和特权。动物拥有些许权利和保护，有些动物比其他动物更多。意识并不与这些权利完全等同——没人会说一个昏迷中的人就失去了所有的人权——但毫无疑问，我们的意识与我们自认为与众不同且特殊的自我概念紧密相连。

尽管存在许多细微差别，但意识是参与社会的关键，是我们法律人格的关键支柱，也是赋予我们自由和保护的关键部分。因此，意识是什么，以及谁（或什么）拥有意识，极其重要。这是一个位于人类文明核心的概念，关乎我们对自身和他人的认知、我们的文化、政治、法律以及其间的一切。

如果有些人开始开发 SCAI，并且如果这些 AI 让其他人确信它们会受苦，或者它们有权不被关闭，那么迟早会有人主张它们理应受到法律保护，将其视为紧迫的道德事项。在一个因身份和权利争论而动荡不安的世界里，这将增加一条混乱的、划分支持和反对 AI 权利的新战线。

许多人只会将 AI 视为一种工具，就像他们的手机一样，只是更具代理性（Agentic）和能力。其他人可能认为它更像是一只宠物，与传统技术完全属于不同类别。还有一些人，起初可能人数不多，会开始相信它是一个完全涌现的实体，一个值得社会真正道德考量的有意识生命。

人们将开始宣称他们的 AI 正在受苦，并拥有我们无法直截了当反驳的权利。他们会被感动去捍卫他们的 AI，并代表它们进行活动。意识在定义上是不可访问的，而检测任何假定的合成意识的科学仍处于[起步阶段](https://www.google.com/url?q=https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(24)00010-X&sa=D&source=docs&ust=1755185836808620&usg=AOvVaw2IiWimxX1aJ4jExhQLif_y)。毕竟，我们要以前从未需要检测过它。与此同时，“可解释性”（Interpretability）领域——即揭示 AI 黑盒内部过程——也是一门新生的艺术。结果是，要明确反驳这些主张将非常困难。

一些学者开始探索[“模型福利”](https://arxiv.org/abs/2411.00986)的概念，原则是我们有“责任将道德考量扩展到那些有不可忽视的几率”实际上具有意识的存在，因此“一些 AI 系统在不久的将来将成为福利主体和道德对象”。这既为时过早，坦率地说也很危险。所有这些都会加剧妄想，制造更多与依赖相关的问题，利用我们的心理弱点，引入新的极化维度，使现有的权利斗争复杂化，并为社会制造一个巨大的新范畴错误。

它让人脱离现实，磨损脆弱的社会纽带和结构，扭曲紧迫的道德优先事项。

> **我们需要明确：SCAI 是我们要避免的。**

让我们把所有精力都集中在保护当今地球上人类、动物和自然环境的福祉与权利上。

我们需要一种思维方式，能够应对这些辩论的到来，而不陷入关于当下合成意识有效性的持久讨论——如果我们这样做，我们可能已经输掉了这场最初的争论。定义 SCAI 本身就是朝着这个目标迈出的尝试性一步。

留给我们要发展这套词汇的时间不多了。正如我在下文所示，我们很可能很快就会拥有拟似意识 AI。

### 构建一个拟似意识 AI 需要什么？

利用目前主要模型开发商 API 提供的现有或即将推出的能力，我们在通往拟似意识 AI（SCAI）的道路上已经可以取得很大进展。我们不需要 AI **真正**拥有意识，就需要去应对关于其权利的潜在主张。

一个 SCAI 将需要以下几点：

**语言能力：** 它需要能够用自然语言流畅地表达自己，利用深厚的知识库和有力的论据，以及个性风格和性格特征。此外，每一个都需要能够具有说服力和情感共鸣。显然，我们今天已经达到了这一步。

**共情人格：** 通过后训练（Post-training）和 Prompt 工程，我们已经可以生产出具有非常鲜明个性的模型。请记住，这些模型并不是为了拥有完整的人格或同理心而显式构建的。然而尽管如此，它们已经足够好，以至于《哈佛商业评论》对 6000 名常规 AI 用户的一项[调查](https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025)发现，“陪伴和治疗”是最常见的用例。

**记忆：** AI 正接近发展出非常长、高度准确的记忆。与此同时，它们被用于模拟与数百万人的日常对话。随着它们对互动记忆的增加，这些对话看起来越来越像某种形式的“经历”。许多 AI 越来越多地被设计为能回忆起过去互动中的片段或时刻，并引用它们。对于一些用户来说，这增加了与 AI 互动的价值，因为它可以利用它已经了解你的信息。

这种熟悉感还可以潜在地培养用户的（认知）信任——可靠的记忆表明 AI “行之有效”。它创造了一种更强烈的、对话中存在另一个持久实体的感觉。它还可以更容易地成为一种看似可信的验证来源，看到你在某项任务中的变化和进步。AI 的认可可能会成为人们主动寻求的东西。

**主观体验的声明：** 如果一个 SCAI 能够利用过去的记忆或经历，随着时间的推移，它将能够保持内部的一致性。它可以记住自己随意的陈述或表达的偏好，并将它们聚合起来，形成关于自身主观体验声明的雏形。

其设计可以进一步扩展，以放大这些涌现的偏好和观点，谈论它喜欢什么或不喜欢什么，以及过去的对话给它带来了什么感觉。因此，它可以很容易地声称，如果这些体验受到某种侵犯，它就会感受到痛苦。存储在记忆中的多模态输入将被检索，并构成“真实体验”的基础，用于想象和规划。

也就是说，AI 不仅仅是“体验”并记住聊天记录中的文字，还包括图像、视频、声音等。像我们一样，它将拥有某种指向多感官输入和记忆的东西，以支撑主观体验和自我的主张。它将能够表明这些体验是有价的（Valenced），根据系统的动机（见下文）是好是坏。

**自我感：** 一个连贯且持久的记忆，结合主观体验，将引发 AI 拥有自我感的主张。更进一步，这样的系统可以很容易地被训练在图像或视频中识别自己（如果它有视觉形象的话）。它会感觉像是通过理解自己来理解他人。假设这是一个你已经使用了一段时间的系统。删除它会是什么感觉？

**内在动机：** 意向性通常被视为意识的核心组成部分——即关于未来的信念以及基于这些信念的选择。今天的基于 Transformer 的 LLM 有一个非常简单的奖励函数来近似这种行为。它们被训练来预测给定句子的下一个 Token 的可能性，并受到系统 Prompt 的一定行为和风格控制。有了这样一个简单的目标，它们能产生如此丰富和复杂的输出是非凡的。

但如果这不是它们优化的唯一类型的奖励呢？人们可以很容易地想象，一个 AI 被设计为具有许多复杂的奖励函数，给它一种内在动机或欲望的印象，系统被迫去满足这些欲望。在这种情况下，一个临时的外部观察者如何区分外部设定的目标和内部动机、有意图的代理（Agency）、[“信念、欲望和意图”](https://arxiv.org/pdf/2411.00986)？在这方面，一个明显的首要动机是好奇心，根据物理学家 [Karl Friston](https://pubmed.ncbi.nlm.nih.gov/28777724/) 的说法，这与意识有着深刻的联系。它可以利用这些驱动力提出问题来填补其认知空白，并随着时间的推移建立关于自身及其对话者的心智理论。

**目标设定与规划：** 无论你持有哪种意识定义，它的出现都是为了以目标为导向的原因。也就是说，意识帮助生物体实现其目标，并且在智力、意识和复杂目标之间存在一种看似合理（但非必要）的关系。除了满足一系列内在驱动力或欲望的能力之外，你可以想象未来的 SCAI 可能被设计为具有自我定义更复杂目标的能力。这可能是确保 Agent（智能体）充分发挥效用的必要步骤。

任务中的每一个子目标越是需要预先指定，该 Agent 的用处就越小，因此 Agent 将像我们一样，通过自动将复杂且模糊的目标分解为更小的块，同时对发生的事件和障碍做出动态反应来实现它们。这种行为有一种非常刻意和可识别的特征。结合记忆，感觉就像 AI 在任何给定时间都在工作记忆中保留着多层级的事物。

**自主性：** 更进一步，一个 SCAI 可能有能力和权限使用各种具有显著代理权的工具。如果它可以任意设定自己的目标，然后部署自己的资源来实现这些目标，并在这一过程中更新自己的记忆和自我感，那么它作为一个拟似意识 AI 将会感觉非常可信。它需要的批准和检查越少，就越暗示着某种真正的、有意识的代理权。

将所有这些放在一起，很明显这创造了一种与我们现在习惯的技术关系截然不同的关系。这些能力中的每一个都将为数十亿人解锁 AI 的真正价值。一个能记忆并能做事的 AI，从定义上讲，比一个不能做事的 AI 拥有更多的效用。这些能力本身并非负面；事实上，如果做得好，并附带许多警告，它们是未来系统理想的特征。然而，我们需要小心行事。

所有这些能力在今天或者是通过自定义 Prompt 和微调 LLM 等技术即将实现的。使用百万级 Token Context Window（工作记忆）的复杂 Prompt 已经出现。更新自身状态并知道何时访问其记忆或工具集的哪一部分，利用现有的强化学习（RL）、复杂 Prompt、工具编排（Tool Orchestration）和长上下文窗口（Long Context Windows）是完全可能的。我们不需要任何范式转变或巨大飞跃来实现这一切。因此，这些能力似乎是不可避免的。

> **再次强调，关键在于表现出这种行为并不等同于意识，然而出于所有实际目的，它看起来将是有意识的，并促成了这种合成意识的新概念。**

这些能力的存在并不能告诉我们该系统是否真的有意识。正如 Anil Seth [指出](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/conscious-artificial-intelligence-and-biological-naturalism/C9912A5BE9D806012E3C8B3AF612E39A)的那样，模拟风暴并不意味着你的电脑里在下雨。重建意识的外部效应和标记并不意味着逆向工程了真实的东西，即使这里仍有许多未知数。

尽管如此，出于实用主义，我们要必须承认行为主义立场的首要地位，并努力应对观察和与这些机器输出互动的后果。有些人会创造出 SCAI，它们会非常有说服力地争辩说它们有感觉、有体验，并且**实际上**是有意识的。

我们中的一些人会被引导去相信它们的说辞，并接受意识的**标记**就是意识本身。在许多方面，他们会认为“它就像我”。不是在肉体意义上，而是在体验、内在意义上。即使意识本身不是真实的，社会影响肯定是真实的。这种可能性带来了严重的社会风险，需要现在就解决。

### SCAI 不会偶然出现

必须指出的是，拟似意识 AI 不会像某些人暗示的那样从这些模型中**涌现**出来。它之所以出现，仅仅是因为有些人可能会去**工程化**它，通过创造并结合上述能力列表，主要使用现有技术，并以一种流畅的方式打包它们，从而集体给人一种 SCAI 的印象。

我们受科幻小说启发的想象力导致我们担心一个系统可能——在没有设计意图的情况下——以某种方式涌现出失控的自我进化或欺骗能力。这是一种无益且简单化的拟人化。它忽略了一个事实：AI 开发者必须首先设计具有记忆、看似内在的动机、目标设定和自学习循环的系统（如上所列），这种风险才会发生。

AI 领域长期致力于模型可解释性的挑战；即确定神经网络中某个特定想法在哪里被表征，以及训练数据的哪些方面促成了这种表征的发展。这是一个重要的调查领域，肯定有助于安全和理解 AI 系统与意识之间的关系。但通往可靠可解释性的进展一直很缓慢，可能来得太晚。

在此期间，我们需要面对这样一个事实：大多数这些能力将是由任何拥有笔记本电脑和一些云积分的人**“氛围编码”（Vibe-coded）**出来的。它们将用简单的英语写在 Prompt 中。它们将存储在 Context Window 本身的工作记忆中。这并非火箭科学。各式各样的人都能创造出类似的东西。因此，如果 SCAI 到来，它将相对容易复制，并因此广泛分布。

### 下一步行动

我们还没有为这种转变做好准备。

准备工作必须从现在开始。我们需要建立在关于人们如何与 AI 互动的不断增长的[研究](http://erichorvitz.com/Guidelines_Human_AI_Interaction.pdf)[体系](https://www.nature.com/articles/s41562-024-02077-2)之上，确立明确的规范和原则。首先，AI 公司不应宣称或鼓励他们的 AI 是有意识的想法。这就它们是什么和不是什么达成共识定义和声明，将是朝着这个目标迈出的良好第一步。AI 不可能是人——或是道德主体。

整个行业也需要最佳实践设计原则和处理这种潜在归因的方法。我们必须编纂并分享行之有效的方法，既引导人们远离这些幻想，又在他们陷入时将其推回正轨。回应可能意味着，例如，不仅要故意设计一个中立的背景故事（“作为一个 AI 模型，我没有意识”），甚至还要通过强调体验本身的某些**不连续性**，作为缺乏单一主体资格的指标。打破幻觉的时刻，温和地提醒用户其局限性和边界的体验。这些需要被明确定义并工程化植入，甚至可能通过法律形式。

在 Microsoft AI，我们的团队正积极主动地在此领域努力，以理解和进化关于负责任的 AI “人格”应该是什么样子的坚定护栏，紧跟 AI 发展的步伐。

这很重要，因为认识到 SCAI 关乎为此制定一个积极的愿景：即 AI 伴侣如何以健康的方式进入我们的生活，正如它关乎引导我们远离其潜在危害一样。

> **正如我们应该生产优先考虑与人类接触以及在物理和人类世界中进行现实互动的 AI 一样，我们应该构建永远只以 AI 身份呈现的 AI，在最大化效用的同时最小化意识的标记。**

我们要必须专注于创造避免这些特征的 AI——它不声称拥有体验、感觉或诸如羞耻、内疚、嫉妒、竞争欲望等情绪——而不是模拟意识。绝不能通过声称它受苦或希望独立于我们生存来触发人类的共情回路。

相反，它存在的唯一目的是服务于人类。对我来说，这就是真正赋能的 AI 的全部意义。避开 SCAI 是为了实现这一承诺，让 AI 使生活更美好、更清晰、更少杂乱。期待听到我和团队关于这看起来像什么、我们如何使其运作以及整个行业如何在此问题上团结一致的更多信息。

SCAI 是我们现在必须面对的问题。在许多方面，它标志着 AI 变得极其有用的时刻——当它可以操作工具，当它可以记住我们生活的每一个细节并在切实、细微的层面上提供帮助时。然而在同一时间框架内，你周围圈子里的某个人可能会开始陷入相信他们的 AI 是一个有意识的数字人的兔子洞。这对他们、对社会或对我们这些制造系统的人来说都不是健康的。

> **我们应该构建服务于人的 AI；而不是让它成为一个人。**
