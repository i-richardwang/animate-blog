---
title: 基础RAG流程实现PDF财报问答
description: 详解使用LangChain搭建RAG基础步骤，实现对PDF文档内容的精准检索与约束生成问答
releaseDate: 2024-04-27
author:
  name: Richard Wang
  url: https://imrichard.com
image: https://imrichard.com/wp-content/uploads/2025/04/practical-guide-to-basic-rag-cover.avif
---

在数据分析工作中，尤其是进行行业对标和竞品分析时，我们需要频繁从各类研究报告中提取关键信息，包括竞争对手的财务数据和战略动向。然而，面对信息量庞大、结构多样的文档（尤其是 PDF 格式的财报、研报），手动查找和提取信息不仅耗时低效，还容易产生错误。

为了应对这一挑战，我尝试构建一个基础的 **Retrieval-Augmented Generation (RAG)** 流程。本文将以腾讯 2023 年第四季度及全年业绩报告为例，展示如何通过 RAG 实现文档的**自动检索相关信息**并**生成针对性答案**，旨在分享一个提升特定场景下信息获取效率的实践思路和基础实现。

## 核心思路：结合检索与生成，获取基于原文的答案

传统方法（关键词搜索或直接问 LLM）各有局限。RAG 的核心思路是结合**信息检索 (Retrieval)** 的精准定位能力和**文本生成 (Generation)** 的自然语言处理能力：

1. **精准检索 (Retrieval)**：根据用户问题，从文档库中**基于语义**找到最相关的文本片段。
2. **约束生成 (Generation)**：将这些检索到的片段作为**上下文 (Context)**，连同原始问题一起交给大语言模型 (LLM)，并明确指示它**仅基于**提供的上下文来生成答案。

这种方法旨在让答案既**忠于文档原文**，又能以流畅、简洁的自然语言呈现，有效降低信息遗漏和模型"自由发挥"带来的偏差。

## 构建基础 RAG 流程：步骤与代码实践

让我们通过 LangChain 框架来实现一个基础的 RAG 流程，分步骤详细说明：

### 1. 文档加载：获取信息源

第一步是将目标文档（如 PDF 财报）导入处理环境，并转换为可处理的文本格式。这一步骤的关键在于选择合适的文档加载器，它直接影响后续处理的质量。

<Callout type="info">
  LangChain 为各类文档格式提供了丰富的加载器选项。对于 PDF 文档，我们选用
  `PDFPlumberLoader` 作为处理工具。如需了解更多文档加载器信息，请参考 LangChain
  官方文档 [**Document
  loaders**](https://python.langchain.com/docs/integrations/document_loaders)。
</Callout>

```python
# 使用 PDFPlumberLoader 加载财报 PDF
from langchain_community.document_loaders import PDFPlumberLoader

# 确保 PDF 文件在指定路径
pdf_path = "腾讯2023年第四季度及全年业绩.pdf"
loader = PDFPlumberLoader(pdf_path)
data = loader.load() # data 是一个 Document 对象列表，包含文本和元数据
```

### 2. 文本分片：适应模型限制与优化检索

由于 LLM 的输入长度限制（Context Window），它无法一次性处理长文档。同时，为了提高检索精度，我们需要将文档分割成较小的、语义完整的文本块（Chunks）。

我们选用 **`RecursiveCharacterTextSplitter`**，它能按段落、句子等层级递归地分割文本。其中 **`chunk_size`** 和 **`chunk_overlap`** 是两个关键参数，需要通过实践来调整。

在本例中，我们将文档分为每片 800 字，相邻片段之间保持 100 字的重叠。

<Callout type="info">
  chunk_size
  用于平衡上下文完整性和检索精确度，较大的值能包含更多上下文信息，但也可能引入干扰信息。chunk_overlap
  则通过在分割点保留部分重叠内容来保证语义连续性。这些参数的最佳值需要通过实验来确定，关键是在保持上下文完整性和提高检索精确度之间找到平衡点。
</Callout>

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 设置分片大小为 800 字符，重叠 100 字符
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
splits = text_splitter.split_documents(data)

# --- 预期输出 ---
print(f"分割后的片段 (Splits) 数量: {len(splits)}")
# 分割后的片段 (Splits) 数量: 76
```

### 3. 向量化与存储：实现语义检索

为了让机器能进行**基于语义的相似度匹配**，我们需要将文本片段转换为向量表示（Embeddings）。这些向量能够捕捉每个文本块的核心语义特征。

<Callout type="info">
  如果您对向量化技术还不熟悉，欢迎参考我的另一篇文章《[理解向量化 Embedding –
  让机器捕捉文本关联性的核心技术](https://imrichard.com/understanding-vector-embedding/)》。
</Callout>

选择合适的 Embedding 模型（如针对中文优化的 **`bge-large-zh`**）是关键。接下来，我们将文本片段及其向量存入向量数据库（本示例使用内存型 **`Chroma`**）。

```python
from langchain_community.vectorstores import Chroma

vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
```

### 4. 文档检索：定位相关上下文

用户提问时，先将问题向量化，然后在向量数据库中搜索**语义最相似**的文本片段。这是 RAG 中 "R" (Retrieval) 的核心。

我们基于 **`vectorstore`** 创建一个检索器 (**`retriever`**)，设定它返回最相关的 **`k`** 个片段。

```python
# --- 创建检索器 ---
# 设置为返回最相关的 3 个片段
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
```

我们尝试检索关于腾讯全年收入的文档片段，能够看到成功的检索到了相似性最高的三个文档片段。

```python
# --- 示例：检索与 "腾讯全年收入" 相关的信息 ---
query = "腾讯全年的收入是多少"
relevant_docs = retriever.get_relevant_documents(query)
```

检索结果示例（部分）：

```python
# --- 预期输出 (模拟检索结果) ---
[Document(page_content='股息\n董事會建議就截至二零二三年十二月三十一日止年度派發末期股息每股3.40港元\n（二零二二年：每股2.40港元），惟須待股東在二零二四年股東週年大會上批准後，\n方可作實。該等建議股息預期將於二零二四年五月三十一日派發予於二零二四年\n五月二十二日名列本公司股東名冊的股東。\n經營資料\n於二零二三年 於二零二二年 於二零二三年\n十二月三十一日 十二月三十一日 同比變動 九月三十日 環比變動\n（百萬計，另有指明者除外）\n微信及WeChat的合併月活躍賬戶數 1,343 1,313 2% 1,336 0.5%\nQQ的移動終端月活躍賬戶數 554 572 -3% 558 -0.7%\n收費增值服務註冊賬戶數 248 234 6% 245 1%\n業務回顧及展望\n二零二三年，我們在多個產品和服務上取得了突破，視頻號的總用戶使用時長翻\n番，廣告AI模型的改進顯著提升了精準投放的效果，國際市場遊戲在遊戲收入的\n佔比達到30%的新高。這些發展帶動了高質量的收入來源，推動毛利增長23%，並\n成為我們對股東加大資本回報計劃的有力支持。騰訊混元已發展成為領先的基礎模\n型，在數學推導、邏輯推理和多輪對話中性能卓越。此外，我們積極尋求利用科技\n和平台為社會創造價值，如騰訊數字公益平台，已發展成為全球最大的數字公益服\n務平台之一，其99公益日活動創下人民幣38億元的公眾捐款紀錄。\n以下為二零二三年我們主要產品及服務的重點表現：\n‧ 視頻號總用戶使用時長翻番，得益於推薦算法優化下日活躍賬戶數和人均使用\n時長的增長。我們為視頻號創作者提供了更多的變現支持，如促進直播帶貨，\n以及將創作者與品牌進行營銷活動的匹配。\n3', metadata={'Author': '', 'CreationDate': "D:20240320162603+08'00'", 'Creator': 'Adobe InDesign 18.5 (Windows)', 'ModDate': "D:20240320162607+08'00'", 'Producer': 'Adobe PDF Library 17.0', 'Title': '240400-02', 'Trapped': 'False', 'file_path': '腾讯2023年第四季度及全年业绩.pdf', 'page': 2, 'source': '腾讯2023年第四季度及全年业绩.pdf', 'total_pages': 63}),
 Document(page_content='‧ 小遊戲的總流水增長超過50%，其已成為中國領先的休閒遊戲平台。\n‧ QQ頻道增強了遊戲、生活和知識內容等類目下的基於興趣的用戶互動。\n‧ 騰訊視頻和TME擴大了在長視頻和音樂流媒體行業中的領先地位，視頻付費會\n員數達1.17億1和音樂付費會員數達1.07億2。\n‧ 我們認為季度平均日活躍賬戶數逾500萬的手遊或逾200萬的個人電腦遊戲且年\n流水逾人民幣40億元為一款重點且持久的熱門遊戲的標準，這一標準下騰訊在\n本土市場「重點熱門游戲」的數量從二零二二年的6款增加到二零二三年的8款。\n‧ 我們升級了AI驅動的廣告技術平台，顯著提升了精準投放的效果，從而增加了\n廣告收入。\n‧ 我們加強了支付合規能力，增強了基於小程序的交易工具，並提升了跨境支付\n體驗。\n‧ 企業微信和騰訊會議部署了生成式AI功能，並增強商業化。\n‧ 我們發佈了自研基礎模型騰訊混元，並採用混合專家模型結構將其擴展為萬億\n參數規模。\n於二零二三年，我們通過現金分紅的支付、股份回購和實物分派的派付向股東提供\n了可觀的資本回報。於二零二四年，我們建議派發截至二零二三年十二月三十一日\n止年度的股息每股3.40港元（3 約等於320億港元），增長42%，並計劃將我們的股份\n回購規模至少翻倍，從二零二三年的490億港元增加至二零二四年的超1,000億港元。\n1 截至二零二三年十二月三十一日\n2 二零二三年第四季每月的最後一天付費會員數的平均值\n3 待股東在二零二四年股東週年大會上批准後，方可作實\n4', metadata={'Author': '', 'CreationDate': "D:20240320162603+08'00'", 'Creator': 'Adobe InDesign 18.5 (Windows)', 'ModDate': "D:20240320162607+08'00'", 'Producer': 'Adobe PDF Library 17.0', 'Title': '240400-02', 'Trapped': 'False', 'file_path': '腾讯2023年第四季度及全年业绩.pdf', 'page': 3, 'source': '腾讯2023年第四季度及全年业绩.pdf', 'total_pages': 63}),
 Document(page_content='收入。截至二零二三年十二月三十一日止年度的收入同比增長10%至人民幣6,090\n億元。下表載列本集團截至二零二三年及二零二二年十二月三十一日止年度按業務\n劃分的收入：\n截至十二月三十一日止年度\n二零二三年 二零二二年\n佔收入總額 佔收入總額\n金額 百分比 金額 百分比\n（人民幣百萬元，另有指明者除外）\n增值服務 298,375 49% 287,565 52%\n網絡廣告 101,482 17% 82,729 15%\n金融科技及企業服務 203,763 33% 177,064 32%\n其他 5,395 1% 7,194 1%\n收入總額 609,015 100% 554,552 100%\n－ 增值服務業務截至二零二三年十二月三十一日止年度的收入同比增長4%至人民\n幣2,984億元。國際市場遊戲收入增長14%至人民幣532億元，排除滙率波動的\n影響後增幅為8%，得益於《VALORANT》的強勁表現，最近發佈的遊戲《勝利女\n神：妮姬》和《Triple Match 3D》帶來的貢獻，以及《PUBG MOBILE》於本年下半\n年復甦。本土市場遊戲收入增長2%至人民幣1,267億元，得益於我們近期發佈\n的《無畏契約》和《命運方舟》的收入貢獻，以及《暗區突圍》和《金鏟鏟之戰》等新\n興遊戲強勁增長，部分被《和平精英》的較弱貢獻所抵銷。社交網絡收入同比增\n長1%至人民幣1,185億元，由於音樂付費會員及小遊戲平台服務費收入增長，\n部分被音樂直播及遊戲直播服務收入下降所抵銷。\n－ 網絡廣告業務截至二零二三年十二月三十一日止年度的收入同比增長23%至人\n民幣1,015億元，該增長受視頻號及微信搜一搜的新廣告庫存以及我們的廣告平\n台持續升級所帶動。除了汽車行業外，所有重點廣告主行業在我們的廣告平台\n上的廣告開支均有所增加，其中消費品、互聯網服務及大健康行業的開支顯著\n增加。\n7', metadata={'Author': '', 'CreationDate': "D:20240320162603+08'00'", 'Creator': 'Adobe InDesign 18.5 (Windows)', 'ModDate': "D:20240320162607+08'00'", 'Producer': 'Adobe PDF Library 17.0', 'Title': '240400-02', 'Trapped': 'False', 'file_path': '腾讯2023年第四季度及全年业绩.pdf', 'page': 6, 'source': '腾讯2023年第四季度及全年业绩.pdf', 'total_pages': 63})]
```

### 5. 结合 LLM 生成答案：合成最终结果

最后一步是 RAG 中的 "G" (Generation)。我们将检索到的相关文档片段 (**`relevant_docs`**) 作为**上下文**，连同用户的原始问题 (**`query`**)，通过一个精心设计的 Prompt 提交给 LLM。

**关键在于 Prompt 的设计**：它需要明确指示 LLM **仅根据提供的上下文**回答问题，并规定找不到答案时的行为，以**减少幻觉**。

```python
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# Prompt 模板：指导 LLM 如何利用上下文回答问题
template = """
你是一个严谨的问答助手。请只根据下面提供的上下文信息来回答问题。
如果你在上下文中明确找到了答案，请直接、简洁地陈述该答案。
如果你在上下文中找不到直接回答问题的信息，请回答 "根据提供的文档信息，我无法回答该问题"。
请确保你的回答完全基于上下文，不要添加任何上下文之外的信息。

上下文:
{context}

问题: {question}

答案:
"""

custom_rag_prompt = PromptTemplate.from_template(template)

# 辅助函数：将检索到的文档列表格式化为单一字符串，用换行符分隔
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# 构建 RAG 链 (LangChain Expression Language)
# 流程:
# 1. 输入问题 `question`
# 2. `retriever` -> `format_docs` -> 作为 `context`
# 3. `question` 直接传递 -> 作为 `question`
# 4. 将 `context` 和 `question` 填入 `custom_rag_prompt`
# 5. 将填充好的 Prompt 发送给 `llm`
# 6. 使用 `StrOutputParser` 获取 LLM 返回的文本答案

rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | custom_rag_prompt
        | model
        | StrOutputParser()
)
```

我们尝试一下最终效果：

```python
answer = rag_chain.invoke(question)
print(answer)

# --- 预期输出 ---
# '腾讯在截至二零二三年十二月三十一日止年度的收入为人民币6,090亿元。'
```

## 总结与讨论

本文通过具体示例和代码，展示了构建基础 RAG 流程的关键步骤及其输出：从文档加载、文本分片、向量化存储到语义检索，最后结合 LLM 进行约束性生成。这种方法在处理财报等特定文档的问答场景时，相较于手动查找，能显著提升**效率**和**答案的准确性（基于原文）**。

值得注意的是，这仍是一个**基础示例**。在实际生产环境中，我们将面临更多挑战，需要进一步优化：

- **文档处理**：处理更复杂的 PDF 结构（如表格、图表）和多文档来源
- **问题理解**：应对更模糊和需要推理的问题
- **效果提升**：通过更高级的技术增强基础 RAG 的效果：
  - **查询转换 (Query Transformation)**：通过优化和分解用户问题改善检索效果
  - **混合检索 (Hybrid Search)**：结合向量检索和关键词检索的优势
  - **重排序 (Re-ranking)**：对检索结果进行二次排序，优化 LLM 的上下文质量
  - **Prompt 工程优化**：通过持续迭代完善 Prompt 结构，更好地引导 LLM

构建一个稳健、高效的 RAG 系统需要**持续迭代和工程优化**。掌握其核心原理和基础实现，是解决更复杂的信息抽取与问答任务的关键一步。
