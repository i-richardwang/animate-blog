---
title: 复刻GPT-Researcher
description: 介绍AI Agent的设计实现，展示如何通过任务分解、并行搜索与内容压缩，构建一个轻量、高效的自动化研究工具
releaseDate: 2024-09-15
author:
  name: Richard Wang
  url: https://imrichard.com
---

最近在关注AI应用项目时，我注意到了 [gpt-researcher](https://github.com/assafelovic/gpt-researcher) 这个项目。在AI Agent概念刚开始兴起的那段时间，这是一个相当知名的实践案例，展示了如何用AI来自动化研究流程。

出于学习目的，我研究了它的设计思路和实现逻辑，并尝试剥离原项目中许多工程化和扩展部分，专注于复刻其核心工作流程。

![Lite Research智能研究工具的主界面截图](/ai/applications/lite-research-ui-overview.webp)

## gpt-researcher项目特点

### 自动化研究流程

gpt-researcher的核心价值在于将传统的人工研究流程自动化：

**传统研究流程**：确定研究范围 → 搜索相关资料 → 筛选有价值内容 → 整理分析信息 → 撰写结构化报告

**自动化流程**：系统接收研究主题 → 自动生成搜索策略 → 并行获取网络信息 → 智能筛选和压缩 → 生成专业报告

### 多步骤任务编排

整个系统的核心特点是将研究任务分解为多个相互协调的处理步骤。首先，系统会根据研究主题的特征自动选择最合适的专家角色，比如金融类问题选择金融分析师角色，技术类问题选择技术专家角色。然后，系统将复杂的研究主题分解为多个更具体的子查询，确保能够全面覆盖研究范围。

在信息收集阶段，系统会并行执行多个网络搜索和内容抓取任务，大幅提高处理效率。获取到原始内容后，系统使用语义分析技术筛选出最相关的内容片段，过滤掉无关信息。最后，根据用户选择的报告类型和语气要求，生成结构化的专业报告。

这种多步骤的任务编排让系统能够处理复杂的研究任务，而不仅仅是简单的搜索结果聚合。每个步骤都有明确的输入输出，步骤之间通过数据流进行连接，形成了一个完整的自动化研究流水线。

## 核心工作流程设计

基于对gpt-researcher的分析，我设计了简化版的工作流程：

![Lite Research自动化研究的核心工作流程图](/ai/applications/lite-research-core-workflow-diagram-scaled.webp)

### 第一步：专家角色选择

系统根据研究主题选择最合适的专家角色。例如：

```
研究主题: "我应该投资苹果股票吗？"
选择角色: 💰 金融分析师
角色描述: "基于数据和趋势，撰写全面、深刻、公正且条理清晰的金融报告"

研究主题: "转售球鞋的商业前景"
选择角色: 📈 商业分析师
角色描述: "基于商业数据、市场趋势和战略分析，制作系统性的商业报告"
```

不同的专家角色会影响后续的分析视角和报告结构。

### 第二步：子查询生成

将复杂的研究主题分解为多个具体的搜索问题：

```python
# 例如研究"人工智能在教育领域的应用"
# 系统可能生成以下子查询：
[
    "AI个性化学习平台现状分析",
    "机器学习在教育评估中的应用",
    "教育AI工具的效果评估研究",
    "AI教育应用的伦理和隐私问题",
    "教育AI技术发展趋势预测"
]
```

这种分解确保研究的全面性，涵盖现状、应用、效果、问题、趋势等多个维度。

### 第三步：并行信息收集与处理

这是整个系统的技术核心，涉及从网络搜索到语义分析的完整链路。传统的搜索方式是逐个处理查询，而这里采用并行处理策略，能够同时对多个子查询进行信息收集和处理。

#### 搜索引擎的选择与调用策略

系统主要使用Tavily API作为搜索引擎，这是因为Tavily专门为AI应用场景设计，它返回的结果已经过结构化处理，包含了标题、内容摘要、URL等字段，比传统搜索引擎更适合程序化处理。当Tavily服务不可用时，系统会自动切换到DuckDuckGo作为备用搜索源，确保整个流程不会因为单一服务的问题而中断。

对于多个子查询的并行处理，系统使用Python的asyncio库实现真正的并发执行。这意味着如果有5个子查询，它们会同时向搜索引擎发送请求，而不是排队等待，这样可以将总的搜索时间从原本的"5×单次搜索时间"缩短到接近"单次搜索时间"。

#### 网页内容的抓取与清洗

搜索引擎返回的是URL列表，系统需要进一步抓取每个网页的具体内容。这个过程使用BeautifulSoup库来解析HTML页面，但不是简单地提取所有文本。网页中包含大量对研究无用的信息，比如导航菜单、广告区域、页脚信息等，这些内容会干扰后续的语义分析。

系统通过识别HTML标签的语义来过滤内容，主要保留 `<article>`、`<main>`、`<p>` 等包含正文的标签内容，同时过滤掉 `<nav>`、`<aside>`、`<footer>` 等导航和辅助信息。此外，还需要处理各种字符编码问题，确保中英文混合内容能够正确显示，避免出现乱码影响后续分析。

#### 文本分片的必要性与实现

即使经过清洗，单个网页的内容往往仍然很长，可能包含几千甚至上万字符。直接将整篇文章送入embedding模型有几个问题：首先是token限制，多数embedding模型对输入长度有限制；其次是语义精度问题，长文本包含多个主题，整体向量化会稀释关键信息的语义特征。

因此系统使用RecursiveCharacterTextSplitter进行智能分片。这个工具不是简单地按字符数切分，而是尽量在句子边界、段落边界进行切分，保持每个片段的语义完整性。每个片段控制在1000-2000字符之间，这个长度既能保持足够的上下文信息，又不会超出模型的处理能力。

#### 向量化与语义相似度计算

文本分片完成后，系统调用embedding API（如OpenAI的text-embedding模型）将每个文本片段转换为高维向量。这些向量能够捕捉文本的语义特征，相似内容的向量在向量空间中距离较近。

当所有内容片段都完成向量化后，系统会计算每个片段与原始查询的语义相似度。这个过程通过计算向量间的余弦相似度来实现，得分范围在0到1之间，分数越高表示内容与查询越相关。系统设置一个相似度阈值（通常是0.7左右），只保留超过阈值的片段，过滤掉语义不相关的内容。

#### 智能压缩与内容精炼

即使经过相似度筛选，剩余的相关内容可能仍然很多。为了避免信息冗余和提高后续分析的精度，系统使用ContextualCompressionRetriever进行进一步的内容压缩。这个组件结合了EmbeddingsFilter和其他压缩算法，不仅考虑语义相似度，还会分析内容的信息密度和互补性。

最终，每个子查询会产生一段高度精炼的上下文信息，这些信息既保持了与查询的高度相关性，又去除了冗余和噪音。这样处理后的内容才适合作为后续报告生成的基础素材。

### 第四步：报告生成

根据选定的报告类型和专家角色生成最终报告：

#### 报告类型的差异化设计

系统提供了多种报告类型以适应不同的使用需求。综合研究报告侧重于对主题进行全面的分析和总结，适合需要深入了解某个领域的场景。资源汇总报告主要整理相关资料和参考文献列表，为后续深入研究提供信息来源。研究大纲类型则提供主要观点和结构框架，帮助用户快速把握主题的整体脉络。

![Lite Research提供的多种报告类型选项，包括综合研究报告、资源汇总报告、研究大纲以及详细深度报告等。](/ai/applications/lite-research-report-type-options.webp)

详细深度报告是功能最完整的类型，它会进一步将主题分解为多个子主题，对每个子主题进行深入分析，最终形成全面且深入的研究成果。自定义报告则允许用户根据特定需求定制报告的内容结构和分析角度。

#### 语气调节的实现机制

除了报告类型，系统还支持语气调节功能，这影响到报告的表达风格和读者定位。正式语气适用于学术研究和商业报告，用词严谨、逻辑清晰。分析性语气强调深度剖析和逻辑推理，突出观点的论证过程。信息性语气以客观呈现事实为主，减少主观判断和情感色彩。解释性语气则面向非专业受众，注重内容的易懂性和可读性。

![Lite Research研究设置中的报告语气选择菜单，展示了客观、批判性、比较性、叙事性等多种可供选择的报告风格。](/ai/applications/lite-research-tone-selection-options.webp)

这些语气选项不仅影响用词和句式，还会调整内容的组织逻辑和信息密度，确保报告能够匹配目标读者的需求和理解能力。

### 详细报告的递进式构建

当选择"详细深度报告"时，系统会执行更复杂的处理流程：

#### 第一阶段：子主题的智能构建

当用户选择详细深度报告时，系统首先会基于前面收集到的所有上下文信息进行深入分析，识别出主要的研究方向和关键议题。这个过程使用LLM来理解内容的主题分布，通常会生成3-8个相关子主题，数量取决于主题的复杂度和信息的丰富程度。每个子主题都有明确的研究重点和覆盖范围，它们之间既相互独立又逻辑关联，确保能够全面覆盖原始研究主题的各个重要方面。

#### 第二阶段：子主题的并行深度研究

子主题确定后，系统会为每个子主题单独执行一轮完整的研究流程。这意味着每个子主题都会重新生成针对性的搜索查询，这些查询比原始的子查询更加具体和深入，能够获取到更专业的信息源。所有子主题的研究过程完全并行进行，没有依赖关系，这样可以充分利用系统的并发处理能力，大幅缩短总体处理时间。

在每个子主题的研究过程中，系统使用与主流程相同的向量检索和语义压缩技术，确保信息质量的一致性。这种设计保证了详细报告中每个部分都有充分的信息支撑，而不会出现某些部分内容丰富、某些部分信息不足的情况。

#### 第三阶段：专业报告的组装与整合

所有子主题研究完成后，系统开始组装最终的详细报告。首先生成整体报告的引言部分，这个引言会建立研究背景和分析框架，为读者提供阅读指引。然后，系统为每个子主题生成独立的专业分析报告，这些报告都基于该子主题收集到的具体信息，保持分析的深度和专业性。

最后，系统按照逻辑顺序将引言和所有子报告组装为一份完整的详细报告。这个组装过程不是简单的内容拼接，而是会处理子报告之间的衔接关系，确保整个报告的逻辑连贯性和阅读流畅性。

#### 并发控制与资源管理

在整个递进式构建过程中，系统实施了多项技术优化措施来确保稳定性和效率。使用asyncio.Semaphore来控制并发数量，避免过多的并发请求对外部API造成压力或触发限流机制。实现了完善的重试机制来处理网络异常和临时服务不可用的情况，确保偶发的错误不会影响整个流程的完成。

![Lite Research执行研究任务的实时进度界面，显示了系统选择的AI代理、生成多个子查询以及并行处理查询的状态。](/ai/applications/lite-research-execution-process-log.webp)

同时，通过LangChain的SQLite缓存机制来减少重复的LLM调用，既提高了响应速度，也有效控制了API使用成本。

## 实际效果展示

下面展示一个实际的研究案例效果：

![Lite Research生成的关于"人工智能在教育领域的应用"的最终报告节选](/ai/applications/lite-research-final-report-example.webp)

## 开源项目

Lite Research 项目已在 GitHub 开源，项目地址为 [https://github.com/i-richardwang/literesearch](https://github.com/i-richardwang/literesearch)。如果你想在本地运行这个项目，只需要克隆代码仓库，然后按照README文档的说明配置相应的API密钥即可启动。

整个项目的技术栈基于Python生态，前端使用Streamlit构建用户界面，通过LangChain框架集成多种LLM API，支持不同的模型提供商。

## 核心在于工作流设计

AI 研究工具的关键不在于使用多么前沿的模型或复杂的技术架构，而在于如何设计工作流程。任务分解、并行处理和智能筛选，这三个环节做好了，即使是相对基础的技术栈，也能实现不错的效果。

当前版本还有很多可以改进的地方，比如更精细的内容去重、更智能的子主题生成等。但基础框架已经可用，代码已开源在 GitHub 上。如果你对 AI 研究工具或相关技术有想法，欢迎在项目中交流讨论。
