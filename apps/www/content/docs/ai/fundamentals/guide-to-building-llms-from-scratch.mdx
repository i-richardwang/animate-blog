---
title: 大模型训练：从零构建流程详解
description: 系列开篇，旨在系统梳理从零构建LLM的完整技术路径、核心环节与实践要点
releaseDate: 2025-04-19
author:
  name: Richard Wang
  url: https://richardwang.me
---

自ChatGPT惊艳亮相以来，大型语言模型（LLM）无疑已经成为人工智能领域最受瞩目的焦点。然而，在一片热议和追捧之中，LLM的**构建过程**本身，似乎仍然笼罩着一层神秘的面纱，它常常被描绘成一项只有少数顶级机构、投入海量资源才能触及的工程奇迹。

训练一个大模型，真的如此遥不可及吗？

诚然，构建顶尖水平、动辄千亿参数的LLM，其对算力、数据和人才的要求确实极高。但这并不意味着理解和掌握其核心的构建流程本身是一件不可能完成的任务。

在这个系列博客中，我希望通过分享在模型训练探索过程中的实践经验，为大家系统性地普及大模型训练的相关知识。无论你是希望未来能亲手构建模型，还是想更深入地理解这些技术的运作原理，都希望这个系列能为你提供有价值的参考。

**本文作为系列的第一篇**，我们将首先从宏观视角出发，一起梳理从零开始构建一个大语言模型的**完整流程框架**，并探讨其中涉及的关键环节和一些重要的考量因素。

## 大模型训练的核心流程概览

那么，从一堆原始文本到一个能理解我们意图的对话模型，这个看似神秘的过程，究竟包含哪些核心步骤呢？实际上，尽管具体实现细节千差万别，但一个完整的大模型训练周期，大致可以遵循一个相对清晰的流程框架，**如下图所示：**

![大语言模型（LLM）核心训练流程概览图，展示了从数据准备到部署监控的关键步骤](/ai/fundamentals/llm-training-process-overview.webp)

**下面我们来逐一分解和探讨这个流程中的关键环节：**

### 数据准备：一切的基础

模型的能力上限很大程度上取决于训练数据的质量和规模。对于参数量达到B（十亿）级别的模型，通常需要T（万亿）级别Token的数据量进行预训练。这不仅仅是简单地收集海量文本。

- **数据收集与清洗：** 需要从多样化的来源（网页、书籍、代码库等）获取数据，并进行严格的清洗，去除噪声、低质量内容、重复数据以及潜在的隐私信息。
- **格式规整与存储：** 将清洗后的数据统一格式，并采用适合大规模并行读取的存储方式（如memmap、TFRecords等），以保证训练过程中的数据加载效率。
- **数据集划分：** 合理划分训练集、验证集和测试集，用于模型训练、超参数调整和最终效果评估。

数据准备本身就是一个耗时耗力的过程，数据的质量直接决定了模型的基础能力和行为偏好。

### 硬件与环境配置：算力的保障

大模型训练对计算资源，特别是GPU显存有着极高的要求。

- **硬件选型：** 需要根据目标模型的规模（如参数量）来规划所需的GPU数量和型号（如NVIDIA A100, H800等）。例如，一个几十B参数量级的模型，即使用FP16混合精度训练，也可能需要数百GB的总显存，这意味着需要数十张高端GPU卡。
- **分布式训练环境：** 单卡往往无法满足训练需求，必须搭建分布式训练环境。这涉及到网络拓扑、节点间通信优化（如NCCL）、分布式策略（如数据并行、模型并行、流水线并行）的选择与配置。
- **软件环境：** 配置好操作系统、CUDA、深度学习框架（如PyTorch、TensorFlow）及其分布式训练库（如DeepSpeed, Megatron-LM），并确保环境的稳定性和兼容性。

硬件和环境的配置是训练得以顺利进行的前提，直接关系到训练效率和可行性。

### 分词器（Tokenizer）训练：连接文本与模型的桥梁

原始的文本数据无法直接被模型处理，需要先通过分词器将其转换为模型能够理解的数字序列（Token ID）。

- **分词（Tokenization）：** 将文本切分成更小的单元（Token）。对于中文，常见做法是按字切分，或者使用基于词的切分。对于英文，常用的是基于子词（Subword）的算法，如**BPE（Byte-Pair Encoding）**或SentencePiece。BPE能够有效处理未登录词（OOV）问题，并通过共享子词来控制词表大小。例如，将 "playing" 分成 "play" 和 "ing"。
- **词表（Vocabulary）：** 分词器会维护一个包含所有不重复Token的词表。词表大小是一个需要权衡的重要因素。过大的词表会显著增加模型输入端Embedding层和输出端预测层的参数量，从而增大模型体积和计算开销。因此，选择合适的分词粒度和词表大小至关重要。按字分词通常能得到较小的词表，但可能损失部分词汇语义；基于子词的算法则在两者间取得较好的平衡。
- **分词器训练：** 虽然很多开源模型提供了预训练好的分词器，但在特定场景下（如处理包含大量专业术语的语料）或希望优化模型效率时，可能需要基于自己的数据训练一个专属的分词器。分词器的训练过程更像是一种基于统计的传统机器学习方法，与神经网络的训练方式不同。

### 模型架构设计：模型的骨架

当前大语言模型的主流架构是**Transformer**。在设计模型时，需要确定：

- **基础架构选择：** 是完全从零开始设计类似GPT或Llama的结构，还是基于某个现有的开源模型架构进行修改和定制。
- **模型参数配置：** 确定模型的层数、隐藏层维度、注意力头数、中间层扩展倍数等关键超参数。这些参数共同决定了模型的总参数量和容量。
- **实现方式：** 可以手写`model.py`文件来精确控制模型结构，或者利用成熟的框架（如Hugging Face Transformers）加载和配置模型。

从零设计提供了最大的灵活性，但也需要更深的理解和更多的开发工作。基于现有架构则能更快地启动。

### 预训练（Pre-training）：奠定通用能力

预训练是整个流程中计算量最大的阶段。其目标是让模型从海量无标注数据中学习通用的语言知识和世界知识。

- **训练任务：** 最常见的预训练任务是**自回归语言建模（Causal Language Modeling）**，即根据前面的Token预测下一个Token（如GPT系列）。也有**掩码语言建模（Masked Language Modeling）**（如BERT系列），通过预测文本中被掩盖的部分来学习上下文表示。
- **基座模型（Base Model）：** 预训练完成后得到的模型通常被称为基座模型。它具备了基本的语言理解和文本生成能力（主要是补全），但还不能很好地遵循指令或进行对话。

预训练的效果直接决定了模型后续在各种下游任务上的潜力。

### 意图对齐微调（Alignment）：让模型"听懂人话"

预训练后的基座模型虽然知识广博，但其行为方式可能与人类期望的交互模式存在偏差，也可能生成不安全或无用的内容。意图对齐旨在解决这些问题。

- **监督微调（Supervised Fine-tuning, SFT）：** 使用高质量的"指令-响应"数据对，训练模型学习遵循指令、进行对话的能力。
- **基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）：** 通过收集人类对模型不同输出的偏好排序，训练一个奖励模型，再利用强化学习算法优化语言模型，使其生成更符合人类偏好的内容。

意图对齐是使模型从"能补全"进化到"能对话、有用且无害"的关键步骤，GPT-3.5（InstructGPT）相对GPT-3的提升很大程度上就归功于此。

### 特定优化微调（Task-specific Fine-tuning）：聚焦特定任务

如果希望模型在某个特定领域或任务（如文本分类、代码生成、特定行业问答）上表现更优，可以在完成意图对齐后，进行针对性的微调。

- **全量微调 vs 高效微调：** 对于大模型，全量微调成本高昂。实践中更多采用**参数高效微调（Parameter-Efficient Fine-tuning, PEFT）**技术，如**LoRA（Low-Rank Adaptation）**。这类方法只调整模型中一小部分参数，就能在特定任务上取得良好效果，大大降低了微调成本。

这一步的目标是提升模型在特定应用场景下的专业能力。

### 模型优化（Optimization）：为部署做准备

训练完成的模型通常体积庞大，推理速度较慢。为了满足实际部署需求，需要进行优化。

- **量化（Quantization）：** 降低模型参数和计算过程的数值精度（如从FP16/BF16降到INT8），减小模型体积，加速推理。
- **剪枝（Pruning）：** 移除模型中冗余或不重要的参数/连接。
- **知识蒸馏（Knowledge Distillation）：** 用一个训练好的大模型（教师模型）指导一个小模型（学生模型）进行学习，使小模型能逼近大模型的性能。

这些技术有助于在保持性能的同时，提高模型的部署效率。

### 部署与监控（Deployment & Monitoring）：走向应用

最后一步是将优化后的模型部署到生产环境，对外提供服务。

- **部署：** 将模型封装成API服务，或嵌入到具体的应用程序中。可能需要使用推理优化引擎（如TensorRT-LLM, vLLM）进一步提升服务效率。
- **监控：** 对线上模型的性能、资源消耗、用户反馈进行持续监控，发现问题并及时迭代优化。

## 从框架到细节

构建大语言模型的完整流程包括：分词器训练、预训练、对齐训练、部署监控。理解这个框架，能帮你把握 LLM 开发的整体脉络，知道每个环节在做什么、为什么要这么做。

每个环节背后都有大量技术细节和实践经验，比如预训练数据该如何清洗、SFT 数据怎样才算高质量、RLHF 的奖励模型如何设计等等。这些都是"祛魅"系列后续文章会深入探讨的话题。

如果你对某个环节特别感兴趣，或者在实践中遇到了具体问题，欢迎交流讨论。
