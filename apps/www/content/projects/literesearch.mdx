---
title: LiteResearch
description: AI 驱动的研究助手，自动进行深度主题研究和结构化报告生成
date: 2024-09-15
category: opensource
tech:
  - LangChain
  - OpenAI
  - Streamlit
  - Tavily
  - Langfuse
  - Python
links:
  github: https://github.com/i-richardwang/LiteResearch
featured: false
---

由大语言模型驱动的 AI 研究工具，帮助用户进行深度主题研究和报告生成。LiteResearch 通过智能 Agent 和并行信息检索，自动化从查询分解到结构化报告生成的整个研究过程。

## 项目背景

基于 [gpt-researcher](https://github.com/assafelovic/gpt-researcher) 开发的简化版本。保留核心概念——通过 AI Agent 实现智能信息检索和报告生成，但简化了实现方式，去除复杂功能模块，使代码结构更清晰易懂。

## 核心功能

**智能 Agent 选择**  
根据研究主题自动选择合适的 AI Agent 角色，如金融分析师、技术专家或领域专家，确保专业知识驱动的研究。

**子查询生成**  
自动生成多个相关的子查询，确保研究覆盖全面。每个子查询针对主题的特定方面，降低遗漏重要角度的风险。

**并行信息检索**  
同时处理多个查询，实现高效的网络信息收集。这种并行方法显著缩短研究时间，同时保持全面性。

**上下文压缩**  
使用向量化技术从搜索结果中提取最相关的内容，避免 LLM 上下文限制问题，同时保留关键信息。

**报告生成**  
生成结构化研究报告，支持多种报告类型和语气风格。每份报告都包含适当的引用和来源链接以供验证。

**LLM 监控**  
集成 Langfuse 监控所有 AI 调用，提供详细的性能分析和成本追踪。这个可选功能有助于优化系统效率。

## 工作流程

LiteResearch 的研究流程分为以下几个阶段：

**用户输入研究主题** → **选择专业 AI Agent** → **生成研究子查询** → **并行处理多个子查询**

每个子查询都会独立进行网络搜索、内容提取和压缩。所有子查询并行执行，这样覆盖面更广，不会遗漏重要角度。例如输入"分析远程工作对企业生产力的影响"，AI Agent 会分解成多个子问题：远程工作的优势、面临的挑战、典型案例、生产力指标变化、管理实践等。

**内容提取与压缩** - 搜索结果包含大量网页，系统逐个访问提取正文内容，去除广告、导航栏等无关信息，只保留核心文本。内容太长会超出 LLM 的上下文限制，使用 LangChain 的文本分割和向量化压缩工具，提取每个网页的关键信息。

**聚合所有上下文** → **报告类型决策**

根据选择的报告类型，系统采取不同的生成策略：

- **详细报告**: 构建研究主题 → 生成报告引言 → 逐个生成主题报告 → 组装完整报告
- **其他类型**: 直接生成最终报告（综合研究报告、资源摘要报告、研究大纲等）

最终生成的报告包含引言、多个主题章节、结论，每个观点都标注来源链接。整个流程通过 Langfuse 监控，可以看到每个子查询的搜索结果、提取的内容、最终的报告。

## 报告类型与风格

系统支持多种报告类型，满足不同的研究需求：

**报告类型**

- **综合研究报告**: 完整的分析和总结，平衡覆盖所有方面
- **资源摘要报告**: 精选的相关资料和参考文献列表，供进一步阅读
- **研究大纲**: 主要观点和结构框架，提供高层次概览
- **详细深度报告**: 全面深入的分析，包含大量细节
- **自定义报告**: 根据用户具体要求定制的报告
- **子主题报告**: 针对特定子主题的深度分析

**语气风格**

- **正式**: 学术和商业报告风格，使用专业语言
- **非正式**: 轻松易读的风格，适合普通读者
- **分析性**: 以深度分析为导向，进行批判性审查
- **说服性**: 旨在影响读者的有说服力的表达
- **信息性**: 客观的信息传递，不带偏见
- **解释性**: 详细的解释和说明，追求清晰度

## 技术栈与架构

### 技术组件

- **Frontend**: Streamlit 提供简洁的 Web 界面
- **Backend**: Python + LangChain 实现 AI 研究工作流
- **AI Models**: OpenAI GPT 系列模型
- **Search Engine**: Tavily API 提供网络搜索能力
- **Vectorization**: OpenAI Embeddings 实现内容压缩和相关性筛选
- **Monitoring**: Langfuse（可选）监控 LLM 调用和性能

### 项目结构

```
literesearch/
├── frontend/                   # 前端应用
│   ├── literesearch_app.py    # 主应用（核心功能逻辑）
│   ├── ui_components.py       # UI 组件和样式定义
│   └── assets/                # 静态资源文件
├── backend/                   # 后端核心
│   └── literesearch/          # 文献研究模块
├── utils/                     # 工具函数
│   ├── llm_tools.py          # LLM 工具类
│   └── langfuse_tools.py     # Langfuse 监控工具
└── pyproject.toml            # 项目配置和依赖
```

### 模块化设计

**职责分离**: `literesearch_app.py` 处理核心功能逻辑，包括用户交互和 AI 研究工作流；`ui_components.py` 负责 UI 组件和样式，处理界面显示和用户体验。这种清晰的职责分离使代码易于维护和扩展。

**核心功能模块**: 包括研究设置和参数配置、AI 研究工作流控制、报告生成和下载、异常处理和用户反馈、LLM 调用监控和分析。

## 高级设置

用户可以通过高级设置控制研究的深度和广度：

- **最大子查询数**: 控制研究广度（1-10），子查询越多，覆盖的角度越全面
- **最大子主题数**: 控制详细报告深度（1-10），适用于详细深度报告类型
- **每个查询最大结果数**: 控制信息量（1-20），影响每个子查询返回的搜索结果数量

## 项目特点

**清晰的代码结构**  
实现更加简化，去除复杂模块同时保留核心逻辑。

**完整的工作流程**  
展示从查询分解、并行检索、内容压缩到报告生成的完整流程。

**可观测性**  
集成 Langfuse 监控，追踪每个阶段的 AI 调用和性能指标。

**灵活的配置**  
支持多种报告类型、语气风格和参数调整。
